{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ldaseq-example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGBK9mLKKtnvTb9mRSJzIr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annie-lyu/word-embedding/blob/master/ldaseq_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKvcJ67COb5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import corpora\n",
        "from gensim.models import ldaseqmodel\n",
        "from gensim.corpora import Dictionary, bleicorpus\n",
        "import numpy\n",
        "from gensim.matutils import hellinger\n",
        "import nltk\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65nEa0dWOwv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eed0175e-5d02-45bf-f458-a45b98406dfe"
      },
      "source": [
        "import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "##folder lists\n",
        "ls = !ls \"/content/drive/My Drive/words/sample\"\n",
        "ls = str(ls).strip(\"'[\")\n",
        "ls = ls.strip(\"]'\")\n",
        "entries = ls.split(\"\\\\t\")\n",
        "entries"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['month1', 'month2', 'month3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVSyq6jyNpzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ae47726b-5284-4d33-8d3f-bdad829bfb35"
      },
      "source": [
        "## preparation for text preprocessing\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = list(set(stopwords.words('english'))) + [\"us\", \"also\", \"said\", \"would\", \"could\", \"mr\", \"get\"]\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "stop_words"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'you',\n",
              " 'haven',\n",
              " 'needn',\n",
              " 'been',\n",
              " 'does',\n",
              " 'no',\n",
              " 'not',\n",
              " 'm',\n",
              " 'we',\n",
              " 'again',\n",
              " \"weren't\",\n",
              " 'hadn',\n",
              " 'of',\n",
              " 'in',\n",
              " 'from',\n",
              " 'the',\n",
              " 'own',\n",
              " 'before',\n",
              " 'while',\n",
              " 'to',\n",
              " 'once',\n",
              " 'when',\n",
              " 'some',\n",
              " 'or',\n",
              " 'them',\n",
              " \"shouldn't\",\n",
              " \"you've\",\n",
              " 'd',\n",
              " \"don't\",\n",
              " 'yours',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"isn't\",\n",
              " 'was',\n",
              " 'whom',\n",
              " \"should've\",\n",
              " 'themselves',\n",
              " 'other',\n",
              " 'its',\n",
              " 'both',\n",
              " 've',\n",
              " \"didn't\",\n",
              " 'myself',\n",
              " \"doesn't\",\n",
              " \"mustn't\",\n",
              " \"mightn't\",\n",
              " 'off',\n",
              " 'because',\n",
              " 'so',\n",
              " \"aren't\",\n",
              " 'isn',\n",
              " 'his',\n",
              " 'as',\n",
              " 'couldn',\n",
              " 'after',\n",
              " 'above',\n",
              " \"you'll\",\n",
              " 'an',\n",
              " \"needn't\",\n",
              " 'few',\n",
              " 'out',\n",
              " 'ma',\n",
              " 'during',\n",
              " 're',\n",
              " 'those',\n",
              " 'my',\n",
              " \"wouldn't\",\n",
              " 'had',\n",
              " 'too',\n",
              " 'himself',\n",
              " 's',\n",
              " 'but',\n",
              " 'very',\n",
              " 'ourselves',\n",
              " 't',\n",
              " 'me',\n",
              " 'there',\n",
              " 'weren',\n",
              " 'i',\n",
              " 'only',\n",
              " 'hers',\n",
              " 'between',\n",
              " 'through',\n",
              " 'itself',\n",
              " 'into',\n",
              " 'down',\n",
              " 'y',\n",
              " 'ours',\n",
              " \"shan't\",\n",
              " 'with',\n",
              " \"you'd\",\n",
              " \"that'll\",\n",
              " 'just',\n",
              " 'shouldn',\n",
              " 'up',\n",
              " 'our',\n",
              " 'their',\n",
              " 'has',\n",
              " 'mightn',\n",
              " 'can',\n",
              " 'yourself',\n",
              " 'he',\n",
              " 'who',\n",
              " 'here',\n",
              " 'they',\n",
              " 'she',\n",
              " 'am',\n",
              " 'hasn',\n",
              " 'if',\n",
              " 'should',\n",
              " 'nor',\n",
              " 'that',\n",
              " 'ain',\n",
              " 'same',\n",
              " 'now',\n",
              " 'at',\n",
              " 'most',\n",
              " 'until',\n",
              " 'a',\n",
              " 'having',\n",
              " 'do',\n",
              " 'all',\n",
              " 'more',\n",
              " 'didn',\n",
              " \"hasn't\",\n",
              " 'these',\n",
              " 'him',\n",
              " 'shan',\n",
              " 'how',\n",
              " 'wasn',\n",
              " \"couldn't\",\n",
              " 'doesn',\n",
              " 'over',\n",
              " 'any',\n",
              " 'doing',\n",
              " 'will',\n",
              " 'which',\n",
              " 'against',\n",
              " 'don',\n",
              " \"she's\",\n",
              " 'mustn',\n",
              " 'below',\n",
              " 'why',\n",
              " 'under',\n",
              " 'herself',\n",
              " 'were',\n",
              " 'each',\n",
              " 'theirs',\n",
              " 'did',\n",
              " 'such',\n",
              " 'being',\n",
              " 'by',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'her',\n",
              " 'where',\n",
              " \"wasn't\",\n",
              " 'is',\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'wouldn',\n",
              " 'be',\n",
              " \"hadn't\",\n",
              " 'than',\n",
              " 'about',\n",
              " 'it',\n",
              " 'for',\n",
              " 'and',\n",
              " 'further',\n",
              " 'll',\n",
              " 'o',\n",
              " \"haven't\",\n",
              " 'then',\n",
              " 'have',\n",
              " 'yourselves',\n",
              " 'on',\n",
              " \"it's\",\n",
              " 'what',\n",
              " 'us',\n",
              " 'also',\n",
              " 'said',\n",
              " 'would',\n",
              " 'could',\n",
              " 'mr',\n",
              " 'get']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL-tSK0HCoU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def removePunctuation(text):\n",
        "    punctuation = '!,;:?\"\\'.-'\n",
        "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
        "    return text.strip().lower()\n",
        " "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkOPo5QszYab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc9e8b5d-f33d-45c6-c6f0-6e4eea8a0ba7"
      },
      "source": [
        "#loading corpus and preprocessing\n",
        "\n",
        "corpus_list= []\n",
        "for entry in entries:\n",
        "    filepath = \"/\".join([\"/content/drive/My Drive/words/sample\", entry, \"*.txt\"])\n",
        "    data_files = glob.glob(filepath)\n",
        "    for data_file in data_files:\n",
        "      document = open(data_file,'r').read().lower()\n",
        "      text = [word for word in document.split()] \n",
        "      corpus = [removePunctuation(word) for word in text]\n",
        "      corpus = [word for word in corpus if not word in stop_words]\n",
        "      corpus_list += [corpus]\n",
        "len(corpus_list)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHJcb5SCZOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0a4aaed-a148-41fa-9eb6-a8cefb31768e"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-94iW0877qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3 Merge corpus into one document\n",
        "with open(\"/content/drive/My Drive/words/sample/BleiCorpus.txt\", 'w') as File:\n",
        "  for corpus in corpus_list:\n",
        "    File.write(\" \".join(corpus)+ \"\\n\" )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bnra6S4NoDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f1615671-3fcd-45fe-de18-4ba088c82306"
      },
      "source": [
        "## establish dictionary \n",
        "dictionary = corpora.Dictionary(corpus_list)\n",
        "dictionary.save(\"/content/drive/My Drive/words/sample/word_dictionary\")\n",
        "\n",
        "\n",
        "## create vocabulary file\n",
        "class MyCorpus(object):\n",
        "    def __iter__(self):\n",
        "        for line in open(\"/content/drive/My Drive/words/sample/BleiCorpus.txt\"):\n",
        "            yield dictionary.doc2bow(line.lower().split())\n",
        "\n",
        "corpus_memory_friendly = MyCorpus()\n",
        "corpus = [vector for vector in corpus_memory_friendly]\n",
        "corpora.BleiCorpus.serialize('/content/drive/My Drive/words/sample/news_corpus', corpus)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D23qtdyL4nBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c1569438-bb60-45aa-a84a-179adc5a04bb"
      },
      "source": [
        "## loading and setting\n",
        "try:\n",
        "  dictionary = Dictionary.load(\"/content/drive/My Drive/words/sample/word_dictionary\")\n",
        "except FileNotFoundError as e:\n",
        "  raise ValueError(\"SKIP: Please download the Corpus/news_dictionary dataset.\")\n",
        "\n",
        "corpus = bleicorpus.BleiCorpus(\"/content/drive/My Drive/words/sample/news_corpus\")\n",
        "\n",
        "time_slice = [438, 429, 456]\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YolsXo6HdUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "768c91d0-6a92-40ed-c76b-578539768764"
      },
      "source": [
        "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c33f36ec4ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mldaseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldaseqmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaSeqModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, time_slice, id2word, alphas, num_topics, initialize, sstats, lda_model, obs_variance, chain_variance, passes, random_state, lda_inference_max_iter, em_min_iter, em_max_iter, chunksize)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# fit DTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_lda_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda_inference_max_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem_min_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mem_max_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_ldaseq_ss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_chain_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_obs_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_suffstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mfit_lda_seq\u001b[0;34m(self, corpus, lda_inference_max_iter, em_min_iter, em_max_iter, chunksize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;31m# fit the variational distribution. This is the M - Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mtopic_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_lda_seq_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_suffstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mbound\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtopic_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mfit_lda_seq_topics\u001b[0;34m(self, topic_suffstats)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting topic number %i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mlhood_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msslm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sslm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_suffstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mlhood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlhood_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mfit_sslm\u001b[0;34m(self, sstats)\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0miter_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mold_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DTM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mupdate_obs\u001b[0;34m(self, sstats, totals)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0;31m# slowest part of method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     obs = optimize.fmin_cg(\n\u001b[0;32m-> 1101\u001b[0;31m                         \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                     )\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DIM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_cg\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             'return_all': retall}\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_cg\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1361\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk, old_fval,\n\u001b[1;32m   1362\u001b[0m                                           \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m                                           extra_condition=descent_condition)\n\u001b[0m\u001b[1;32m   1364\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    844\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mderphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnewargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mdf_obs\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m   1632\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DTM\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DTM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m         \u001b[0mderiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msslm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_obs_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_deriv_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DIM\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0mderiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msslm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_obs_deriv_fixed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msslm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_deriv_mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderiv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa:F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/ldaseqmodel.py\u001b[0m in \u001b[0;36mcompute_obs_deriv\u001b[0;34m(self, word, word_counts, totals, mean_deriv_mtx, deriv)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain_variance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mterm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                 \u001b[0mterm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_deriv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit_mult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mterm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifjJSW042MpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e53d2580-3686-4bcd-8c6d-3d1ad0f008e6"
      },
      "source": [
        "#Printing Topics\n",
        "ldaseq.print_topics(time=0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('-', 0.008138278623003488),\n",
              "  ('best', 0.00722372065121603),\n",
              "  ('\"i', 0.003934130706098536),\n",
              "  ('said', 0.0036999887694496108),\n",
              "  ('also', 0.0036959581622512064),\n",
              "  ('would', 0.003585114741708679),\n",
              "  ('game', 0.0034908308346543954),\n",
              "  ('last', 0.0032523035753691384),\n",
              "  ('one', 0.0031271346991542407),\n",
              "  ('first', 0.003118835596116297),\n",
              "  ('two', 0.002962258656993341),\n",
              "  ('play', 0.002930826166947557),\n",
              "  ('chelsea', 0.0028835498994196204),\n",
              "  ('win', 0.0027817720829047764),\n",
              "  ('players', 0.0027509820025130847),\n",
              "  ('club', 0.002691209454365762),\n",
              "  ('\"we', 0.0026885415940103136),\n",
              "  ('united', 0.00267593149993234),\n",
              "  ('league', 0.002576014943323031),\n",
              "  ('think', 0.0025063518687069982)],\n",
              " [('said', 0.011476252321617105),\n",
              "  ('-', 0.007431551340182253),\n",
              "  ('us', 0.007130325291501011),\n",
              "  ('also', 0.004444234242588271),\n",
              "  ('new', 0.004319346995075073),\n",
              "  ('last', 0.003648447774472637),\n",
              "  ('would', 0.0035846050470246535),\n",
              "  ('could', 0.0035544552450907235),\n",
              "  ('year', 0.00344925406338575),\n",
              "  ('said.', 0.003272644102724381),\n",
              "  ('market', 0.0030255136595839574),\n",
              "  ('sales', 0.0026948336757255014),\n",
              "  ('growth', 0.0026716353319577568),\n",
              "  ('bank', 0.0025101763408022634),\n",
              "  ('economic', 0.002488088655352715),\n",
              "  ('oil', 0.0023455394541666797),\n",
              "  ('company', 0.0023430278628423585),\n",
              "  ('mr', 0.0022367014341071203),\n",
              "  ('economy', 0.0021805248290035005),\n",
              "  ('\"the', 0.002148911681266272)],\n",
              " [('people', 0.01006924217745161),\n",
              "  ('said', 0.01002262022743161),\n",
              "  ('mobile', 0.00579400709844084),\n",
              "  ('net', 0.004818694929279096),\n",
              "  ('one', 0.004798273234673492),\n",
              "  ('technology', 0.004646274947069357),\n",
              "  ('use', 0.0044934013036896986),\n",
              "  ('mr', 0.004458521571089385),\n",
              "  ('users', 0.004306547306770331),\n",
              "  ('many', 0.004099917213828829),\n",
              "  ('also', 0.0038628701856685942),\n",
              "  ('phone', 0.003676191829305361),\n",
              "  ('using', 0.0035296649855775172),\n",
              "  ('information', 0.003502345534364125),\n",
              "  ('could', 0.003431209767426152),\n",
              "  ('would', 0.0032751035304235516),\n",
              "  ('new', 0.003253818621806359),\n",
              "  ('get', 0.003232066709356153),\n",
              "  ('search', 0.0031903073908821204),\n",
              "  ('-', 0.0031554065574275)],\n",
              " [('said', 0.008621444883408588),\n",
              "  ('new', 0.007361899304232224),\n",
              "  ('also', 0.0052308609316591296),\n",
              "  ('-', 0.004604893219616356),\n",
              "  ('one', 0.004454371291068522),\n",
              "  ('mr', 0.004157601019880432),\n",
              "  ('number', 0.0041431063938940065),\n",
              "  ('music', 0.004092632937990803),\n",
              "  ('would', 0.004050613162817593),\n",
              "  ('people', 0.003795744484248887),\n",
              "  ('first', 0.0037437383309955018),\n",
              "  ('show', 0.0032106325992572993),\n",
              "  ('top', 0.0032068032616886736),\n",
              "  ('tv', 0.0031195195656219333),\n",
              "  ('uk', 0.003073009432266584),\n",
              "  ('us', 0.0030455427605062934),\n",
              "  ('software', 0.002827835645544397),\n",
              "  ('bbc', 0.0028127376562842917),\n",
              "  ('said.', 0.002718312049097359),\n",
              "  ('could', 0.0026407347005034136)],\n",
              " [('mr', 0.018132462583044035),\n",
              "  ('said', 0.016444164709918118),\n",
              "  ('would', 0.009627059011899801),\n",
              "  ('-', 0.005882316698817964),\n",
              "  ('government', 0.005471493160505781),\n",
              "  ('blair', 0.004329160975530985),\n",
              "  ('told', 0.0042499615889118655),\n",
              "  ('people', 0.004131974281707053),\n",
              "  ('minister', 0.0038554919439942347),\n",
              "  ('also', 0.0037862728915465035),\n",
              "  ('labour', 0.0036647217611741134),\n",
              "  ('said.', 0.0036513181372938),\n",
              "  ('new', 0.0036399866817435718),\n",
              "  ('said:', 0.003411178781484378),\n",
              "  ('could', 0.003372020852581884),\n",
              "  ('public', 0.002998429512233235),\n",
              "  ('prime', 0.002796799021755872),\n",
              "  ('party', 0.0027281235756962505),\n",
              "  ('election', 0.0027278706417792073),\n",
              "  ('\"i', 0.0025850740953830354)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzJ4sjGjgyZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Topic Evolution\n",
        "ldaseq.print_topic_times(topic=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC_meLDnhGQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## word distribution in a specific document\n",
        "words = [dictionary[word_id] for word_id, count in corpus[558]]\n",
        "print (words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klj5xSciiWne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## A specific document's latent topic distribution\n",
        "doc = ldaseq.doc_topics(558)\n",
        "print(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VEyQgVhiu8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_football_1 = ['economy', 'bank', 'mobile', 'phone', 'markets', 'buy', 'football', 'united', 'giggs'] #make up a news about how football affect economy\n",
        "doc_football_1 = dictionary.doc2bow(doc_football_1)\n",
        "doc_football_1 = ldaseq[doc_football_1]\n",
        "print (doc_football_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXkMBjiJkSCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## topic distance between documents (hellinger distance: measure similarity of two distribution)\n",
        "doc_football_2 = ['arsenal', 'fourth', 'wenger', 'oil', 'middle', 'east', 'sanction', 'fluctuation']\n",
        "doc_football_2 = dictionary.doc2bow(doc_football_2)\n",
        "doc_football_2 = ldaseq[doc_football_2]\n",
        "hellinger(doc_football_1, doc_football_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dmOwe4mlq2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## changing rate of topic factors(words in topics)\n",
        "ldaseq.print_topic_times(1)\n",
        "\n",
        "##Note: the chain_variance parameter could affect the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aWaBXzhwfrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}